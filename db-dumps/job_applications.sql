--
-- PostgreSQL database dump
--

\restrict dTHEIxdZqGbPp3JceGX5JjoG77waC0nZYVTThSSabGKagzNgz3pnLKewbbg4Jfa

-- Dumped from database version 15.14 (Debian 15.14-1.pgdg13+1)
-- Dumped by pg_dump version 15.14 (Debian 15.14-1.pgdg13+1)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Data for Name: vacancies; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.vacancies (id, status, date_created, date_updated, source_url, title, job_description, job_poster, import_source) FROM stdin;
2	published	2025-10-30 15:52:08.473+00	2025-10-30 16:00:46.972+00	https://www.linkedin.com/jobs/view/4332442558/	Senior Python Developer	Senior Backend Engineer (Django) ‚Äì Remote Europe | ‚Ç¨100k + Equity\n\n\nFoxley Talent's client is a fast growing creative AI startup on a mission to make visual creation effortless. Their web and mobile apps with Django at their core use cutting edge generative technology to help millions of users produce professional quality imagery in seconds and empowering creators, small businesses, and global brands alike.\n\n\nWith hundreds of millions of downloads and billions of assets processed annually, the platform operates at massive scale, blending world class design with serious engineering. They are profitable, expanding quickly, and now hiring a Senior Backend Engineer with expertise in Django to join their (almost fully remote) European team.\n\n\nThe Role\n\nAs a Senior Backend Engineer, you‚Äôll help design and deliver new features for a high volume, user centric platform. You‚Äôll work closely with other engineers, product teams, and data specialists to keep the system fast, reliable, and intuitive.\n\n\nYou‚Äôll own your work end to end: from architecture and implementation to monitoring and optimisation. Expect to iterate quickly, release often, and see your code impact millions of users around the world.\n\n\nWhat You‚Äôll Be Working On\n\n    Build and maintain scalable backend services using Python, Django, and Django REST Framework\n    Collaborate with frontend teams using TypeScript, React, and GraphQL to design efficient APIs\n    Optimise and refactor existing endpoints to reduce latency and support large-scale traffic\n    Design and evolve relational database schemas (PostgreSQL) and manage migrations with minimal downtime\n    Monitor performance and reliability using tools such as Datadog and Sentry\n    Ship frequently in an agile, experimentation driven environment\n    Contribute to architectural discussions, tooling improvements, and developer experience\n\n\nKey Requirements\n\n    5+ years of experience building backend systems with Python and Django\n    Solid understanding of relational databases and query optimisation at scale (100GB+)\n    Experienced in designing and documenting APIs for internal and external use\n    Strong sense of ownership. It helps if you care deeply about quality, reliability, and speed!\n    Pragmatic and product focused. Valuing iteration and simplicity over "over engineering"\n    Fluent in English and comfortable working remotely across time zones\n\n\nNice to haves\n\n    Familiarity with GCP or similar cloud platforms\n    Exposure to large scale consumer or creative tech products\n    Experience working closely with design driven or AI focused teams\n\n\nThe Offer\n\n    ‚Ç¨100k base salary (flexible for exceptional profiles) this will be paid through an employer of record service like Deel\n    Equity package / stock options\n    Fully remote across Europe, with paid travel for quarterly team meetings\n    30 days paid leave + local public holidays\n    Annual learning & development budget\n    Home office setup budget or co-working allowance\n    Private health coverage and wellness support\n\n\nHow To Apply\n\nApply now through Foxley Talent to find out more about this new opportunity. Send your latest CV and reasons for your interest in the role to hello@foxleytalent.com and we will review your application.\n\n\nPlease note, this role is ONLY open to those currently based in Europe and no applications from residents outside of this region will be considered.\n\nThe company is not offering visa sponsorship or relocation.\n\nPlease only apply if you are in the location specified.	Foxley Talent	linkedin
1	published	2025-10-30 14:29:32.244+00	2025-10-30 16:01:00.64+00	https://www.linkedin.com/jobs/view/4332717701/	Senior Full Stack Engineer - Profitable AI Startup	Senior Full Stack Engineer (Remote ‚Äì Europe)\n\n\nSartre is partnered with a profitable, independent AI startup founded by experienced engineers who previously built large-scale systems at top tech companies. They‚Äôre building modern data and infrastructure platforms that power advanced AI applications, and are now expanding their small, senior engineering team across Europe.\n\n\nWe‚Äôre looking for a Senior Full Stack Engineer who enjoys building reliable systems end to end, someone comfortable working across backend services, APIs, and front-end interfaces. The ideal candidate has experience in fast-paced startups, strong backend skills, and a generalist mindset.\n\n\nWhat You‚Äôll Do\n\n    Design, build, and maintain full-stack applications and internal data tools.\n    Work closely with founders and senior engineers to deliver production systems.\n    Contribute ideas on architecture, automation, and product design.\n    Help scale tools and workflows used in high-performance AI environments.\n\n\nWhat We‚Äôre Looking For\n\n    5+ years of software engineering experience.\n    Degree in Computer Science, Engineering, or a related technical field, or equivalent practical experience\n    Proven track record in a reputable, fast-moving product company or startup.\n    Strong in Python or Java, with JavaScript (experience with Django and Svelte is a plus).\n    Hands-on experience building backend-heavy systems or workflow tools.\n    Curious, self-driven, and comfortable working with autonomy.\n\n\nWhy This Role\n\n    Build systems used by leading AI companies.\n    Work directly with experienced founders in a small, high-ownership team.\n    Fully remote, most of the team within Europe\n    Competitive compensation and meaningful equity for early joiners.\n\n\nIf you‚Äôre an experienced full-stack or backend engineer who wants to work on technically interesting products in a small, high-impact environment, I‚Äôd love to share more.\n\n\nLocation: Remote (Europe preferred)\n\nExperience: 5+ years\n\nTech: Python, TypeScript, Django, Svelte (or similar)\n\nProcess: Intro chat ‚Üí Take-home ‚Üí Technical and culture interviews	Sartre Group	linkedin
3	published	2025-11-03 13:52:27.441+00	2025-11-03 15:11:13.54+00	https://www.linkedin.com/jobs/view/4333275011/	Fullstack Software Developer	Job Title: Fullstack Engineer\n\n\nJob Type: Full-time\n\n\nLocation: Remote\n\n\nAbout Us:\n\n\nThe AI platform for human intelligence‚Äîwe build models that rigorously vet PhDs and scale human data training for frontier LLMs.\n\n\nOur agent, Zara, autonomously sources and evaluates world-class researchers and data trainers‚Äîpowering post-training (RLHF, evals, red-teaming) for top AI labs, modernizing staffing firms, and helping startups hire their core AI teams.\n\n\nAbout the Role:\n\nJoin us as a Fullstack Software Engineer to design, build, and scale high-impact applications from front to back. You‚Äôll architect robust APIs, craft intuitive interfaces, and deploy secure, cloud-native solutions. We value engineers who write clean code, communicate clearly, and thrive in collaborative environments.\n\n\nKey Responsibilities:\n\n    Develop, deploy, and maintain REST APIs and microservices using Python (FastAPI/Flask) or Node.js (TypeScript/Express/Koa).\n    Build performant, maintainable frontend applications using React.js and Next.js (SSR, SSG, dynamic routing, API routes).\n    Implement state management with Redux Toolkit, Zustand, or React Query.\n    Design and optimize PostgreSQL schemas and queries for scalability and reliability.\n    Create responsive, pixel-perfect UIs with TailwindCSS and Styled Components.\n    Integrate with internal/external APIs (e.g., Slack, Google Sheets).\n    Deploy, monitor, and secure apps using AWS (EC2, S3, Lambda, CloudFront, etc.) and Nginx.\n    Maintain clean, well-documented code and participate in code reviews.\n\n\nWhat We're Looking For:\n\n    Deep hands-on experience with React.js, Next.js, and TypeScript.\n    Proven ability to build and scale backend systems in Python or Node.js.\n    Strong understanding of state management, asynchronous programming, and PostgreSQL optimization.\n    Experience with AWS and Nginx in production environments.\n    Exceptional attention to UI detail and cross-browser responsiveness.\n    Excellent communication and collaboration skills.\n\n\nNice to Have:\n\n    Experience with workflow automation, CI/CD, Docker/Kubernetes, or Infrastructure as Code (Terraform, Ansible).\n    Familiarity with Pydantic, advanced TypeScript types, and performance optimization for distributed systems.	micro1	linkedin
4	published	2025-11-03 16:12:07.459+00	2025-11-03 16:21:27.464+00	https://sveltejobs.com/jobs/full-stack-developer-for-innovative-projects-at-penbrothers-8ab4	Full-Stack Developer for Innovative Projects	    You'll work on everything from sleek, intuitive UIs for our customers to backend services that process and integrate AI-transformed orders.\n    Build and refine web applications using Svelte/React for customer-facing and internal tools.\n    Develop backend services in Go, connecting to Postgres databases.\n    Collaborate with AI engineers to integrate OpenAI and in-house ML models into production workflows.\n    Work with Kubernetes (K8s) to deploy and scale services.\n    Ensure smooth data flow into ERP systems with a focus on reliability and correctness.\n    Contribute to product design, from brainstorming UX flows to shaping technical architecture.\n\nRequirements\n\n    Strong experience in modern frontend frameworks (Svelte and/or React or similar technologies).\n    Solid knowledge of backend languages (Go, Python, etc.)\n    Comfort with Postgres and relational data modeling.\n    Familiarity with Kubernetes, Docker, and cloud-native deployments.\n    Experience integrating APIs (bonus if with AI/LLM APIs like OpenAI).\n    A product-focused mindset: you care about end-users and real-world impact.\n    Ability to thrive in a small, collaborative team with lots of autonomy.\n\nBenefits\n\n    Meaningful work & Growth: We take every opportunity to stretch ourselves and deliver an excellent client experience.\n    Employee as our biggest asset: We are genuinely invested in our people‚Äôs career and welfare.\n    Global reach & local impact: Get to work with high-growth startups and dynamic companies from the comfort of your own home.\n    Powering global startups: We‚Äôve created 1,400 Filipino jobs that empower global start-ups to focus on growth.	Penbrothers	svelte_jobs
5	published	2025-11-03 16:33:34.294+00	\N	https://www.linkedin.com/jobs/view/4332169828/	Python Software Developer (Fully Remote)	Senior Software Engineer \n\n\nKey Responsibilities:\n\n    Design and implement scalable, maintainable, and well-documented systems and APIs.\n    Develop and maintain services in Python with a strong focus on Django, async programming, typing, pydantic, and pytest.\n    Apply SOLID principles, data structures, and algorithms to ensure clean, maintainable code.\n    Build and integrate systems in event-driven architectures.\n    Develop solutions leveraging YANG models, gNMI/gNOI protocols, and industry API specifications (TMF API, OpenAPI).\n    Contribute to cloud-native development workflows, including Docker, Helm, and Ansible.\n    Collaborate with cross-functional teams to ensure system reliability, performance, and security.\n    Write clear documentation and contribute to knowledge-sharing within the team.\n\n\nRequired Skills & Experience:\n\n    High proficiency in Python, with practical experience in Django, Typing, Pydantic, Pytest.\n    Strong background in systems/API/interface design and documentation.\n    Experience with event-driven architecture.\n    Experienced in YANG modeling, gNMI/gNOI protocols, and API standards (TMF, OpenAPI).\n    Hands-on experience with cloud-native technologies: Docker, Helm, Ansible.	Moralis	linkedin
6	published	2025-11-04 13:17:14.906+00	2025-11-04 13:17:53.078+00	https://www.linkedin.com/jobs/view/4333609605/	Full Stack Software Engineering Position	Join The Team Reinventing How The World Rents.\n\nAt The Flex, we believe renting a home should be as effortless as ordering an Uber.\n\nOur mission is bold: to make renting borderless, instant, and intelligent.\n\nThrough Base360.ai ‚Äî our proprietary platform ‚Äî we‚Äôre building the digital nervous system of the rental world: connecting property data, automating operations, and creating an intelligent layer that powers every stay, everywhere.\n\nIf you‚Äôre an engineer who thrives at the intersection of automation, AI, and real-world impact, this is your chance to help redefine how millions live and move.\n\nüí° What You‚Äôll Build\n\nAs a Full Stack Engineer, you‚Äôll architect and scale the systems behind The Flex ‚Äî from frictionless guest journeys and automated check-ins to predictive pricing and operational intelligence.\n\nYou‚Äôll work across the stack and across continents, turning complex real estate problems into clean, efficient, and scalable solutions.\n\nYou won‚Äôt just ship features ‚Äî you‚Äôll engineer efficiency, eliminate friction, and build the backbone of the intelligent rental economy.\n\n‚öôÔ∏è Your Mission\n\n    Build the Core ‚Äì Develop scalable, high-performance web apps that power bookings, payments, and automation workflows.\n    Automate Everything ‚Äì Design AI-driven scripts and microservices to eliminate repetitive manual tasks.\n    Integrate Intelligently ‚Äì Build and optimize APIs linking Base360.ai with key platforms like Airbnb, Stripe, and Twilio.\n    Ship Fast, Scale Smart ‚Äì Manage and deploy cloud infrastructure (AWS, serverless) for speed, reliability, and growth.\n    Solve Problems That Matter ‚Äì Tackle challenges like global booking sync, predictive pricing, and live operational insights.\n    Collaborate Deeply ‚Äì Partner with product, operations, and data teams to bring automation from code to reality.\n\nüß† You‚Äôre a Great Fit If You Have\n\n    Strong experience with Node.js, React, and AWS (serverless stack preferred).\n    Expertise in designing and scaling API-first architectures.\n    Familiarity with FastAPI/Python for automation or data pipelines (bonus points).\n    A passion for building clean, production-grade systems that scale globally.\n    Curiosity about automation, real estate tech, and AI-driven operations.\n    A bias for action ‚Äî you build fast, learn faster, and love solving hard problems.\n\nüåç Why You‚Äôll Love It Here\n\n    Real Impact ‚Äì Your code will power thousands of stays and disrupt a $4T industry.\n    Global Mission, Lean Team ‚Äì No silos. No bureaucracy. Just top performers building fast.\n    Growth Mindset ‚Äì We iterate quickly, embrace feedback, and scale what works.\n    Performance-Driven Rewards ‚Äì Competitive pay + meaningful upside for exceptional contributors.\n    Remote-First Culture ‚Äì Work from anywhere. We care about results, not hours.\n\nüö´ Do Not Apply If\n\n    You‚Äôre looking for a safe, predictable 9‚Äì5.\n    You prefer talking over building.\n    You‚Äôre comfortable being average.\n    You‚Äôre not aiming to be among the top 1% in your craft.\n\n	Flex Living	linkedin
7	published	2025-11-05 11:18:57.9+00	2025-11-05 11:19:49.98+00	https://www.linkedin.com/jobs/view/4320062959/	Senior Software Engineer - Full Stack	We believe the future of marketing is word-of-mouth. Our trusted referral platform puts word-of-mouth marketing on autopilot by rewarding users (and affiliates) for sharing the product they love! The only all-in-one referral platform for B2B SaaS.\n\n\nWe‚Äôve raised $8.3M total funding led by top-tier investors, and we‚Äôre now looking for a Senior Software Engineer(m/f/x) to help us realize our committed vision.\n\n\nüöÄ Why join\n\n    Unique growth opportunity: early-stage GrowthTech start-up backed by top-tier investors ($8.3M total funding).\n    Complex and interesting product: APIs, attribution models, recommendation engines, and more.\n    Strong momentum: SaaS companies need cost-effective sales channels ‚Üí we‚Äôre the solution.\n    Build the engineering culture you‚Äôd recommend to your ex-colleagues.\n    We onboard 15+ new customers every month and already reach 6M+ monthly users.\n    Work with an experienced founding team (ex-Twilio, Wise, Skype).\n\n\nüåü What We‚Äôre Building\n\nWe help SaaS companies turn users into their best sales channel. Our platform powers referrals, sharing & recommendations - used by millions monthly.\n\n\nTech stack includes:\n\n    Frontend widgets embedded into customer apps.\n    High-performance APIs for seamless integrations.\n    Full customer portal for managing campaigns & analytics.\n\n\nUnder the hood: attribution models, recommendation engines, scaling millions of events ‚Äî much more than a simple web app.\n\n\nYour Mission\n\nWe are currently looking for a Senior Full Stack Engineer (m/f/x).\n\n    Stack: NestJS ¬∑ Python ¬∑ AWS ¬∑ React\n    Work directly with stakeholders - no walls, no ticket factory.\n    Build new features and improve existing systems.\n    Pragmatic balance:\n    Sometimes we ship fast to learn, sometimes we slow down to fix the foundation - you‚Äôll help decide where to lean.\n    Have real influence on architecture and product direction - not just coding tickets.\n\n\nAbout You\n\nRequired\n\n    Good communication skills and a friendly, collaborative attitude\n    Good English skills (written&spoken)\n    You know when ‚Äúgood enough‚Äù is right - and when to invest in quality\n    Solid experience: NestJS/Python or similar, and AWS is a must, React or similar\n    Comfortable debugging complex problems\n    Contribute ideas, challenge assumptions, shape solutions\n    Use AI tools wisely, but don‚Äôt depend on them\n\n\nNice-to-haves\n\n    Experience with mobile development (React Native, Flutter, etc.)\n    Familiarity with data warehousing / analytics (e.g. Snowflake, ClickHouse, or similar)\n\n\nCompany Benefits\n\n‚ù§Ô∏è In the end it‚Äôs all about the team and our culture. Understand why we love our job and see what it‚Äôs like to work at Cello in our People Playbook. We have some compelling perks and benefits.\n\n    Competitive, adjustable compensation based on your appetite between equity/cash\n    vESOPs based on the generous Index Ventures guidelines, which sets us apart from most European startups\n    Remote-first global company with local hubs. We hire the best, senior people regardless of location\n    Flexible office allowance to support your hybrid or fully-remote working model\n    Build your perfect setup to do the best work of your life. Mac/Windows, plugins, cutting-edge tech stack‚Ä¶ Tell us what you need to be productive and we will take care of it\n    Monthly learning allowance to satisfy your thirst for growth and lifelong learning\n    Quarterly culture weeks where we come together, celebrate and set the course for the coming months. We have chosen to work remotely, but we encourage frequent face-to-face time	Cello	linkedin
\.


--
-- Data for Name: applications; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.applications (id, status, date_created, date_updated, vacancy, profile, cv_sent_through, cv_file_sent, application_sent_date, discontinued_reason, discontinued_note, application_note) FROM stdin;
2	draft	2025-10-30 15:52:08.475+00	2025-10-30 16:03:07.894+00	2	2	\N	\N	\N	\N	\N	\N
1	applied	2025-10-30 15:30:59.676+00	2025-11-03 14:07:03.403+00	1	2	linkedin_easy_apply	398e0a7c-8e2d-4fb1-a83f-6d6faf55d500	2025-11-01	\N	\N	\N
4	discontinued	2025-11-03 16:12:07.464+00	2025-11-03 16:23:37.478+00	4	2	\N	\N	\N	It's a remote job, but for in the Philippines. Maybe a bit too far out of my timezone..	\N	\N
3	discontinued	2025-11-03 14:06:02.338+00	2025-11-03 16:32:09.751+00	3	2	custom_form	05fde889-f95b-4041-8d92-6e43df495fd9	2025-11-01	Crazy hard interview questions..	\N	\N
5	discontinued	2025-11-03 16:33:34.298+00	2025-11-03 16:34:53.571+00	5	2	\N	\N	\N	No experience with YANG modeling	\N	\N
6	applied	2025-11-04 13:19:50.161+00	2025-11-05 11:03:37.392+00	6	2	custom_form	\N	2025-11-05	\N	\N	\N
7	applied	2025-11-05 11:22:14.852+00	2025-11-05 12:06:58.996+00	7	2	custom_form	\N	2025-11-05	Application form didn't work	Needed to create a password in last step, but got 400 response with "an error occured. we are working on this"	Application form went to cord.com and I signed up there and now I can find jobs over there, but I'm not sure if my application was actually sent to this company. Cord.com is a platform where you can find jobs.
\.


--
-- Data for Name: application_interview_questions; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.application_interview_questions (id, sort, date_created, date_updated, application, question, answer) FROM stdin;
1	\N	2025-11-03 14:35:35.011+00	2025-11-03 14:36:36.554+00	3	In React.js with TypeScript, how would you design a custom hook to manage optimistic updates for a real-time collaborative feature, ensuring type safety and handling potential rollback scenarios?	\N
4	\N	2025-11-03 14:37:03.851+00	2025-11-03 14:37:25.266+00	3	Propose a concrete TypeScript signature like: useOptimisticUpdate(opts: { key: QueryKey; apply(p: Patch): Item; mutate(p: Patch): Promise; resolve?(server: Item, local: Item): Item; onError?(e): void; }) What would it return?	\N
7	\N	2025-11-03 14:38:15.489+00	\N	3	Briefly, how would you model version IDs and reconciliation so late server acks don‚Äôt overwrite newer local state?	\N
3	\N	2025-11-03 14:36:54.955+00	2025-11-03 14:37:25.273+00	3	Briefly outline the hook‚Äôs signature: arguments, return values, and generics. What types would you use for Item, Patch, MutationResult, and ConflictResolver?	\N
2	\N	2025-11-03 14:36:47.947+00	2025-11-03 14:37:25.279+00	3	How would you structure the hook‚Äôs API (inputs/returns), and coordinate local cache, server mutation, rollback, and conflict resolution with React Query or SWR while preserving strict TypeScript types?	\N
5	\N	2025-11-03 14:37:42.924+00	\N	3	What should the hook return to be ergonomic? Specify fields like optimisticItem, isMutating, error, applyPatch, commit, rollback, and how they integrate with React Query‚Äôs setQueryData/invalidateQueries.	\N
6	\N	2025-11-03 14:37:53.887+00	\N	3	How would you ensure rollback integrity across concurrent patches (e.g., queue with versioning vs. snapshot stack), and prevent double-apply when React re-renders?	\N
8	\N	2025-11-03 14:38:30.85+00	2025-11-03 14:38:56.924+00	3	Imagine a multi-tenant FastAPI service handling heavy read/write traffic. How would you design request scoping, DB session management, and tenant data isolation to ensure performance, security, and observability? Walk me through your approach‚Äîhigh level‚Äîto implement per-request scoped SQLAlchemy sessions in FastAPI without leaking connections under high concurrency?	\N
9	\N	2025-11-03 14:39:09.166+00	\N	3	How would you handle transaction boundaries and retries for transient errors (e.g., deadlocks, serialization failures) while preserving idempotency across FastAPI endpoints?	\N
10	\N	2025-11-03 14:39:20.318+00	\N	3	How would you design idempotency keys for POST endpoints (storage, TTL, request/response hashing), and ensure safe retries across multiple workers without race conditions?	\N
11	\N	2025-11-03 14:39:30.6+00	\N	3	How would you enforce tenant isolation at the DB layer: separate schemas vs. separate databases vs. row-level security? Explain trade-offs and operational impacts.	\N
12	\N	2025-11-03 14:39:53.648+00	\N	3	You‚Äôre migrating a multi-tenant PostgreSQL system to AWS. Compare using RDS PostgreSQL vs Aurora PostgreSQL for bursty, read-heavy workloads with strict tenant isolation. What would you choose and why?	\N
13	\N	2025-11-03 14:40:05.518+00	\N	3	How would you enforce strict tenant isolation at the database layer: separate clusters, schemas with RLS, or separate databases? Justify trade-offs and operational impact.	\N
14	\N	2025-11-03 14:40:16.071+00	\N	3	In a high-throughput OLTP system with mixed OLAP queries, how would you design partitioning (range/list/hash), indexing, and autovacuum settings in PostgreSQL to minimize bloat and hotspots on AWS?	\N
15	\N	2025-11-03 14:40:25.769+00	\N	3	How would you architect a resilient, cost-efficient cross-region disaster recovery strategy on AWS for PostgreSQL, including RPO/RTO targets, backup/restore, replication, and failover testing?	\N
16	\N	2025-11-03 14:40:36.018+00	\N	3	For cross-region DR on AWS PostgreSQL, what RPO/RTO would you target and why, and how would you validate them with automated failover drills?	\N
17	\N	2025-11-03 14:40:52.074+00	\N	3	Let‚Äôs move to security: Design a least-privilege, audit-ready access model for PostgreSQL on AWS. Cover IAM auth vs passwords, secrets rotation, pg_hba, roles/permissions, and auditing.	\N
18	\N	2025-11-03 14:41:08.02+00	\N	3	Imagine you‚Äôre designing a multi-tenant, event-driven analytics platform (billions of events/day) with strict data isolation. How would you partition data, design schemas, and enforce isolation across services and storage?	\N
19	\N	2025-11-03 14:41:19.951+00	\N	3	At that scale, trade-offs matter. How would you design the event ingestion path to handle bursts (10x spikes) while guaranteeing ordering per tenant and exactly-once processing semantics?	\N
20	\N	2025-11-03 14:41:57.884+00	\N	3	Balancing ordering and exactly-once under bursts is tricky. How would you handle idempotency and deduplication across the ingestion bus, stream processor, and sinks without sacrificing throughput?	\N
21	\N	2025-11-03 14:42:13.023+00	\N	3	How would you structure code and boundaries (modules, packages, interfaces) to keep this platform maintainable over years, minimizing coupling while enabling independent deployability?	\N
22	\N	2025-11-03 14:43:03.788+00	\N	3	Imagine a multi-tenant SaaS on PostgreSQL (RDS) with 20k tenants, each with spiky workloads. Would you choose schema-per-tenant, table-partition-per-tenant, or row-level tenancy? Explain trade-offs for performance, isolation, maintainability, and cost on AWS.	\N
23	\N	2025-11-03 14:43:25.113+00	\N	3	How would you design auto-scaling and connection management on AWS (RDS + PG + possibly PgBouncer/Lambda/ECS) to prevent connection storms and protect primary?	\N
24	\N	2025-11-03 14:43:45.484+00	\N	3	How would you cap and pool connections end-to-end‚Äîapp ‚Üí PgBouncer ‚Üí RDS‚Äîwhile ensuring transaction pooling safety and avoiding session-level features that break under pooling?	\N
25	\N	2025-11-03 14:44:07.06+00	\N	3	How would you optimize query performance in PostgreSQL for a high-read application on AWS, incorporating read replicas, caching with ElastiCache, and indexing strategies?	\N
26	\N	2025-11-03 14:44:40.274+00	2025-11-03 14:45:06.133+00	3	Imagine you inherit a monolith with tangled business logic, poor test coverage, and frequent regressions. How would you incrementally refactor it to improve maintainability without halting feature delivery? Could you outline your first three concrete steps you‚Äôd take in the first month, including how you‚Äôd measure progress and reduce regression risk?	\N
27	\N	2025-11-03 14:46:08.652+00	\N	3	What are the top three architectural seams you‚Äôd identify to start carving out modules, and how would you enforce boundaries (code, repo, and runtime) to prevent backsliding?	\N
29	\N	2025-11-04 13:29:56.534+00	2025-11-05 10:56:36.522+00	6	Tell us about something you've done in the past that can be considered as evidence of exceptional ability	At Chipta, I've led teams of 3-5 developers for over 7 years, where we built an innovating ticketing platform. I worked along-side the founder, made technical strategic decisions, and led the technical projects. I took great responsibility for scaling the platform to be able to handle thousands of orders per minute. I Optimized SQL queries and Python processes up to 60%, implemented comprehensive testing suites, and orchestrated CI/CD systems. I oversaw the creation of a React Native mobile app that contributed to a 40% revenue increase. I architected REST APIs and modernized frontend interfaces with React and Lit (Web Components), increasing user engagement by 30%. The platform has processed tens of millions in transactions and served hundreds of event organizers. I successfully led the technical growth from a startup to a competitive player on the Dutch ticketing market.
30	\N	2025-11-05 11:55:27.392+00	\N	7	What skills are you most interested in using next?	1. Svelte\n2. Headless CMS\n3. LLMs (Large Language Models)\n4. FastAPI\n5. Machine Learning
31	\N	2025-11-05 11:56:49.564+00	\N	7	Which industries are you most interested in?	- Software Development\n- Machine Learning and AI\n- Computer and Network Security
28	\N	2025-11-04 13:29:56.531+00	2025-11-05 10:24:59.168+00	6	Tell us about a time when you "hacked the system" to your advantage	I'm currently creating a system for myself to help me find and apply for jobs. I'm using AI implementations (OpenAI, Gemini) to find the best matching jobs that meet my preferences. Various modules in the system help me with different tasks, like customizing my resume / CV, writing suitable cover letters, answering common application questions, and preparing for interviews. The system also gives an overview of your applications, where I can see and update the status and other details.\n\nAnother time I created my own fully customized desktop environment using awesome-wm and lua scripts. This DE is lightweight, simplistic, but feature-complete, and highly keyboard driven. It supports multiple desktops, multiple monitors, and it remembers and restores the location and position of windows across reboots. Because I can fully customize it and configure endless keyboard shortcuts, it allows me to work very efficiently. This setup ties in nicely with my tmux and Neovim workflows.
\.


--
-- Data for Name: application_questions; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.application_questions (id, sort, date_created, date_updated, question, answer, title, profile, source) FROM stdin;
1	1	2025-10-20 12:33:01.867+00	2025-10-20 15:25:34.417+00	Tell us about your experience building a project with a Python backend.\n\n- What kind of project was it?\n- What technologies and frameworks did you use (e.g., Flask, FastAPI, Django, etc.)?\n- (Optional) Please share a link (GitHub repo, live demo, or case study) if available.	At Chipta I've build the Django backend from the ground up. I attached Django to an existing database, enabling a smooth transition from the previous system. I even modified Django to work with an existing translation system.\n\nI added React to the project for dynamic frontend pages, and used Django REST Framework to create APIs accommodating the React frontend. Many APIs were for admin pages so needed authentication and permission checks. I also implemented pagination, nested routing (using drf-nested-routers), filtering (using django-filter), field-based filtering (using drf-flex-fields), and custom APIs with custom urls.\n\nChipta is a ticketing system for event organizers. They can use the system to create a ticket shop and sell their tickets online. I've scaled the system to be able to handle thousands of ticket orders per minute. To optimize the SQL queries and Python processes, I used tools like Django Silk and Django Debug Toolbar.\n\nChipta has processed millions of euros in transactions. I developed the ticketshop, API and server processes that handle these transactions. I used payment provider SDKs to create the payments and forward users to the payment page.\n\nTo mail the tickets to users, I used Django's EmailMultiAlternatives class to send pretty HTML emails including inline images, not requiring loading external resources.\n\nTo create ticket PDFs, I used Django-WeasyPrint, which uses Weasyprint under the hood, and transforms a Django HTML template, including styles and images, to a PDF file.\n\nI used Python Fabric to build a comprehensive custom CI/CD pipeline to deploy the project to our servers.\n\nI used Selenium to write integration tests to automatically test our frontend.\n\nYou can sign up and create a ticketshop yourself at: https://chipta.com/	Python backend building experience	2	AuditOne
3	2	2025-10-20 13:49:08.162+00	2025-10-20 14:23:38.115+00	Have you built or worked on systems that manage a lot of structured information or documents (e.g., internal platforms, CRMs, audit systems, or similar)? *\n\n- Describe what the system did and how you contributed.\n- What kind of data or documents were handled?\n- How did you design the backend (APIs, database, integrations, etc.)?\n- (Optional) Did you add any AI-powered or automation features using Python?	At Tender-it, I created a Django + Celery project that ran web crawlers that scraped tender data from various sources in various formats, then parsed that data into one format and saved it to the database. A A tender is a formal competitive bidding process for contracts, usually big government projects. The scripts would import thousands of tenders each day. Then I created a web platform with an Elasticsearch-based search engine to search, filter, sort and score these tenders.\n\nSome sources offered a REST API with JSON or structured data in some way. In those cases it was easy to get the data parse it. But many sources had out-of-date technology, and I needed to use unconventional methods to get the data, like website scraping, API reverse engineering, zip files with XML files over FTP, CSV files over email.\n\nSo I created a base class for importing the data and a base class for parsing the data. Then for each source I created a class, inheriting the base class and implementing the required methods. The base classes provided many helper methods for implementing common functionality. Like this I could easily add new sources.\n\nI imported all structured data into the MariaDB database. Then I created records in Elasticsearch with all the data that should be search-able, with a reference to the complete data in the database. In this way I could use Elasticsearch to efficiently find the desired record, and when found, fetch the complete info from the database.	Data management system experience	2	AuditOne
4	3	2025-10-20 14:25:16.929+00	2025-10-20 15:22:56.279+00	Tell us about a project where you built or shipped a full-stack application. What was your role, and what technologies did you use?	At Chipta, I led a project creating a ticket scanning app, to scan and validate event entrance tickets, using the phone camera. I decided on using React Native, and guided a medior developer to set up the project and make architectural decisions. I focused on providing the REST APIs and the related business logic.\n\nThe scan app would often be used by multiple people at the same time. So I had to make sure to keep the scan apps synchronized, so the same ticket could not be used multiple times. I used a websocket connection between the apps and the Django backend, using Django Channels. With an open websocket connection, I could instantly send data from the app to the backend and vice-versa, without any request overhead. This allowed me to create a custom protocol to send various types of data, like ticket scans, or undo-ing a scan, or even adding more valid tickets.\n\nWhen an app scanned a ticket, it send data about it to the backend over the websocket connection. Then the backend would broadcast this scan data to the other scan apps with open websocket connections, synchronizing the apps. Also, if an administrator would update the status of a visitor's ticket in the backend, it would also be broadcasted over the websockets.\n\nWe also created functionality for offline usage. The scan app would locally cache the tickets, and if the internet connection would be temporarily gone, still be able to scan tickets. After connection came back, it would restore synchronization and have custom conflict resolution in case of conflicts.\n\nThe scan app was successfully released on the Google Play Store and Apple App Store, under the name "Chipta". Hundreds of event organizers have successfully used it to validate tickets from over a million of visitors at their events. The app was very important for Chipta's growth as it significantly reduced custom scanner hardware costs and management, and  contributed to a 40% revenue increase in the 2 years after the release.\n\nChipta in the Google Play Store:\nhttps://play.google.com/store/apps/details?id=com.chipta\n\nChipta in the Apple App Store:\nhttps://apps.apple.com/us/app/chipta/id1156524548	Full-stack app building experience	2	AuditOne
\.


--
-- Data for Name: outsourcing_platforms; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.outsourcing_platforms (id, status, sort, date_created, date_updated, name, url, type) FROM stdin;
1	published	1	2025-11-05 13:57:34.253+00	\N	Turing	https://developers.turing.com/	vetted_platforms
12	published	2	2025-11-05 14:13:29.44+00	2025-11-05 14:16:28.509+00	cord	https://cord.com/	vetted_platforms
2	published	3	2025-11-05 14:00:22.861+00	\N	Toptal	https://www.toptal.com/	vetted_platforms
3	published	12	2025-11-05 14:00:45.365+00	\N	Lumenalta	https://lumenalta.com/	agencies
5	published	11	2025-11-05 14:01:25.02+00	\N	micro1	https://www.micro1.ai/careers	vetted_platforms
10	published	4	2025-11-05 14:05:27.066+00	\N	X-Team	https://x-team.com/	midlance_platforms
4	published	5	2025-11-05 14:01:00.275+00	\N	Upwork	https://www.upwork.com/	open_marketplaces
11	published	6	2025-11-05 14:11:27.988+00	\N	We Work Remotely	https://weworkremotely.com/	job_boards
9	published	7	2025-11-05 14:04:51.943+00	\N	Gigster	https://gigster.com/	midlance_platforms
6	published	8	2025-11-05 14:02:44.443+00	\N	Arc.dev	https://arc.dev/	open_marketplaces
7	published	9	2025-11-05 14:03:17.286+00	\N	Gun.io	https://gun.io/	open_marketplaces
8	published	10	2025-11-05 14:04:00.605+00	2025-11-05 14:04:07.967+00	Andela	https://www.andela.com/	vetted_platforms
\.


--
-- Data for Name: platform_profiles; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.platform_profiles (id, status, sort, date_created, date_updated, profile, outsourcing_platform) FROM stdin;
1	profile_in_progress	\N	2025-11-05 14:49:03.765+00	\N	2	12
2	profile_in_progress	\N	2025-11-05 16:08:53.722+00	\N	2	1
3	profile_in_progress	\N	2025-11-05 16:09:26.783+00	\N	2	4
4	vetting_declined	\N	2025-11-05 16:09:46.763+00	2025-11-05 16:17:59.699+00	2	5
\.


--
-- Data for Name: salary_expectations; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.salary_expectations (id, sort, date_created, date_updated, job_title, company_type, employment_type, work_arrangement, region, hourly_rate, month_salary, year_salary, daily_rate, profile) FROM stdin;
1	1	2025-10-28 12:14:10.169+00	2025-11-03 15:58:58.101+00	Senior Python SWE	enterprise	fte	remote	eu_west_north	35	6000	80000	280	2
5	2	\N	2025-11-03 16:01:14.095+00	Senior Python SWE	enterprise	contract	remote	eu_west_north	70	12000	145000	550	2
3	\N	2025-10-29 14:44:32.844+00	2025-11-03 16:02:12.201+00	Senior Full-Stack SWE	agency	contract	remote	eu_east_south	60	10000	125000	450	2
\.


--
-- Data for Name: vacancy_resources; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.vacancy_resources (id, sort, date_created, date_updated, name, url, file, vacancy) FROM stdin;
1	\N	2025-11-03 15:11:13.541+00	\N	Interview Instructions	https://www.micro1.ai/interview-questions	\N	3
2	\N	2025-11-03 16:12:50.076+00	\N	Application Form	https://penbrothers.recruitee.com/o/senior-full-stack-developer-1	\N	4
3	\N	2025-11-04 13:17:53.082+00	\N	Application URL	https://jobs.ashbyhq.com/The-Flex/54dd2207-c091-4823-8d9b-20bc59b911c4	\N	6
4	\N	2025-11-05 11:19:49.982+00	\N	Application form	https://cord.com/u/cello/jobs/20876-senior-software-engineer---fullstack?listing_id=20876	\N	7
\.


--
-- Name: application_interview_questions_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.application_interview_questions_id_seq', 31, true);


--
-- Name: applications_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.applications_id_seq', 7, true);


--
-- Name: outsourcing_platforms_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.outsourcing_platforms_id_seq', 12, true);


--
-- Name: platform_profiles_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.platform_profiles_id_seq', 4, true);


--
-- Name: salary_expectations_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.salary_expectations_id_seq', 12, true);


--
-- Name: vacancies_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.vacancies_id_seq', 7, true);


--
-- Name: vacancy_resources_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.vacancy_resources_id_seq', 4, true);


--
-- PostgreSQL database dump complete
--

\unrestrict dTHEIxdZqGbPp3JceGX5JjoG77waC0nZYVTThSSabGKagzNgz3pnLKewbbg4Jfa

